{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f35477-f7d5-4a3b-b739-9b9857a7a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\StockPricePrediction\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import PatchTSTConfig, PatchTSTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e0fc0-f242-4518-ab1d-cb5e3eb3b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7cf6d98-2df8-4d15-9dc9-f916b0a01177",
   "metadata": {},
   "source": [
    "# Patch TST Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aeb99289-8fd8-48f5-a927-5cf8cd22455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length=200\n",
    "num_input_channels=3\n",
    "patch_length=8\n",
    "config = PatchTSTConfig(\n",
    "            num_input_channels=num_input_channels,\n",
    "            context_length=context_length,\n",
    "            patch_length=patch_length,\n",
    "            use_cls_token=True,  # Ensure CLS token usage is set correctly\n",
    "            # Additional configurations can be added here if needed\n",
    "        )\n",
    "base_model = PatchTSTModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3fe3800-7862-4c59-87ee-6c9ea6dba0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = base_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928ac5d-a139-456b-8f50-f224c9e814c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d941e606-ca24-4bac-a5c7-d8c7e842f656",
   "metadata": {},
   "source": [
    "# Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e12d6e7-daba-42bc-86f8-7ca427e0a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_values = torch.randn(32, context_length, num_input_channels).cuda()  # (batch_size, context_length, num_input_channels)\n",
    "output = base_model(past_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a104b69-25d4-4fec-a556-f878917b9f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'loc', 'scale', 'patch_input'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24c2e6c7-956b-4cf8-a3d6-e739943061c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 10, 128])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a569e-0456-4cc0-b29b-9224eea0001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomPatchTSTClassifier(\n",
    "    num_input_channels=10,\n",
    "    context_length=128,\n",
    "    patch_length=16,\n",
    "    num_classes_per_category=3,\n",
    "    num_categories=4,\n",
    "    use_cls_token=True\n",
    ")\n",
    "\n",
    "# Example input tensor\n",
    "past_values = torch.randn(32, 128, 10)  # (batch_size, context_length, num_input_channels)\n",
    "\n",
    "# Forward pass\n",
    "logits = model(past_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1368daaa-5f8c-4c80-ac6b-56d12a73e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1154f416-8318-480f-ab89-66eff0d85db3",
   "metadata": {},
   "source": [
    "# Custom PatchTSTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "88a8c07c-e0bb-429d-964f-d09f0321c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomPatchTSTClassifier(nn.Module):\n",
    "    def __init__(self, num_input_channels, context_length, patch_length,\n",
    "                 num_classes_per_category=3, num_categories=4, use_cls_token=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Configure PatchTSTModel\n",
    "        self.config = PatchTSTConfig(\n",
    "            num_input_channels=num_input_channels,\n",
    "            context_length=context_length,\n",
    "            patch_length=patch_length,\n",
    "            use_patch_pe=True,        # Ensure positional encoding is used\n",
    "            use_vars_per_channel=True # Depending on your data\n",
    "        )\n",
    "        self.base_model = PatchTSTModel(self.config)\n",
    "\n",
    "        # Retrieve hidden size from the base model configuration\n",
    "        hidden_size = self.config.hidden_size\n",
    "\n",
    "        # Single classification head for all categories\n",
    "        self.fc = nn.Linear(hidden_size, num_categories * num_classes_per_category)\n",
    "\n",
    "        # Option to use CLS token or mean pooling\n",
    "        self.use_cls_token = use_cls_token\n",
    "\n",
    "        # Store other parameters\n",
    "        self.num_classes_per_category = num_classes_per_category\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "    def forward(self, past_values):\n",
    "        # Get hidden states from PatchTSTModel\n",
    "        outputs = self.base_model(past_values=past_values)\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
    "        print(f'hidden_state from patchtst base model is {hidden_states.shape}')\n",
    "\n",
    "        # Use CLS token state or mean pooling based on the hyperparameter\n",
    "        if self.use_cls_token:\n",
    "            output_state = hidden_states[:,:,0, :]  # Assuming CLS token is at position 0\n",
    "            output_state = output_state.mean(dim=1)\n",
    "        else:\n",
    "            output_state = hidden_states.mean(dim=2).mean(dim=1) \n",
    "\n",
    "        print(f'pre-head shape {output_state.shape}')\n",
    "        # Generate logits for all categories\n",
    "        logits = self.fc(output_state)  # Shape: (batch_size, num_categories * num_classes_per_category)\n",
    "        print(f'post_head shape {output_state.shape}')\n",
    "        # Reshape logits to (batch_size, num_categories, num_classes_per_category)\n",
    "        logits = logits.view(-1, self.num_categories, self.num_classes_per_category)\n",
    "\n",
    "        return logits  # Returns tensor of logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ff4cd08e-e623-4aa8-a229-a7102f760819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_state from patchtst base model is torch.Size([32, 3, 193, 128])\n",
      "pre-head shape torch.Size([32, 128])\n",
      "post_head shape torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "context_length=200\n",
    "num_input_channels=3\n",
    "num_classes_per_category=3\n",
    "num_categories=4\n",
    "patch_length=8\n",
    "custom_model= CustomPatchTSTClassifier(num_input_channels=num_input_channels,\n",
    "                                 context_length=context_length,\n",
    "                                 patch_length=patch_length,\n",
    "                                 #hidden_size=hidden_size,\n",
    "                                 num_classes_per_category=num_classes_per_category,\n",
    "                                 num_categories=num_categories,\n",
    "                                    use_cls_token=True)\n",
    "custom_model = custom_model.cuda()\n",
    "past_values = torch.randn(32, context_length, num_input_channels).cuda()  # (batch_size, context_length, num_input_channels)\n",
    "output = custom_model(past_values)\n",
    "probabilities = torch.softmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff49914b-6cac-4308-bb0e-770f272fa2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(output, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f40b7d2c-8936-4761-a9e5-bfb65496dd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 3])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a4334-8a6e-4ac4-88a0-5f237dbdc9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
